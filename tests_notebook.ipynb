{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eszna\\miniconda3\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NUM_FRAMES = 8\n",
    "INPUT_NUM_SHOTS = 16\n",
    "INPUT_NUM_SAMPLES = 513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 513])\n",
      "tensor([[[ 0.3035,  0.0546, -1.8916,  ...,  0.0229, -0.8479, -0.2714],\n",
      "         [-0.0520,  0.9667,  1.6239,  ...,  1.1671,  0.2802,  0.2478],\n",
      "         [ 1.2496,  0.8742,  1.5610,  ...,  0.2361, -0.2178, -0.5147],\n",
      "         ...,\n",
      "         [-0.3502, -1.5130, -1.0031,  ..., -0.8323,  0.5058,  0.0280],\n",
      "         [-0.8373,  0.2329,  0.6382,  ..., -0.6497, -1.2095, -0.0677],\n",
      "         [ 1.1621, -2.0406, -0.7588,  ..., -0.3055,  1.8073,  0.7462]],\n",
      "\n",
      "        [[-0.0577,  1.9125,  0.1380,  ..., -0.5996,  0.4904, -0.7886],\n",
      "         [-0.5222, -0.3170,  1.1275,  ..., -0.3599, -0.6733,  0.5488],\n",
      "         [ 0.1797,  0.9448,  1.3894,  ...,  0.0269, -1.3711, -0.8472],\n",
      "         ...,\n",
      "         [ 0.6028, -1.6825, -0.1903,  ...,  0.5838, -0.7490, -0.9237],\n",
      "         [ 0.4963,  0.6166, -1.5584,  ...,  0.8379, -0.6498,  0.5276],\n",
      "         [ 0.2459, -0.9257,  0.5477,  ...,  0.3721,  0.5308,  0.3349]],\n",
      "\n",
      "        [[-1.4432, -0.7390, -1.0185,  ..., -1.2737, -1.5779,  0.4508],\n",
      "         [-0.2570, -0.4559,  0.3486,  ...,  0.1218, -0.0607, -0.1160],\n",
      "         [-0.1522, -0.6516, -0.2797,  ...,  1.6883, -0.7692, -0.3441],\n",
      "         ...,\n",
      "         [-1.0727,  0.4548,  1.0693,  ...,  0.6199,  1.0252, -1.1215],\n",
      "         [ 0.6331, -0.0248,  1.0849,  ..., -1.0755, -0.0253, -0.6629],\n",
      "         [-1.3429,  0.5365, -0.3179,  ...,  0.8539, -2.2093,  0.4515]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6506, -0.6469, -0.1133,  ...,  2.1997,  0.6663,  0.8907],\n",
      "         [-0.0312, -1.5287, -0.3658,  ...,  0.4224, -0.2448,  2.3559],\n",
      "         [ 0.4496,  1.6257, -0.8541,  ..., -0.4881,  0.0802,  0.4508],\n",
      "         ...,\n",
      "         [-1.7432,  0.3703, -0.8512,  ..., -1.1720,  0.2484, -0.2141],\n",
      "         [ 1.3690,  0.6605, -1.2171,  ...,  1.3661,  0.7354,  1.1691],\n",
      "         [ 0.7853, -0.5270,  1.1622,  ..., -0.1084, -1.1714,  0.3158]],\n",
      "\n",
      "        [[ 0.7741, -2.2349, -0.6208,  ..., -1.7740,  1.9309,  1.2408],\n",
      "         [ 0.3879, -1.2418,  0.6097,  ...,  0.6755, -0.7522, -0.1091],\n",
      "         [ 0.5406, -0.1107, -1.1418,  ..., -0.0256,  1.1071,  1.1469],\n",
      "         ...,\n",
      "         [ 0.1345,  0.8927, -1.1740,  ..., -1.7730, -0.1735,  0.8142],\n",
      "         [-0.2387, -0.3177, -0.2730,  ...,  0.7579, -1.1148, -0.7494],\n",
      "         [ 0.2364, -1.3824, -0.5650,  ..., -0.2345,  0.7409, -1.2591]],\n",
      "\n",
      "        [[ 0.5258, -0.5673,  0.2724,  ...,  1.1930,  1.1274, -2.0965],\n",
      "         [ 0.7690, -0.1230, -0.0724,  ..., -0.2902, -1.4089,  0.6966],\n",
      "         [ 0.8605,  0.1823, -1.1505,  ...,  0.3055, -0.3824,  0.5436],\n",
      "         ...,\n",
      "         [-0.2966, -0.0494,  0.8627,  ...,  0.4464,  0.9783, -3.0731],\n",
      "         [ 0.1238, -0.5597, -0.3715,  ..., -0.0309,  1.0419, -0.7406],\n",
      "         [-1.4921, -1.0052,  1.9393,  ...,  1.7178,  0.8182,  0.7712]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = th.randn(INPUT_NUM_FRAMES, INPUT_NUM_SHOTS, INPUT_NUM_SAMPLES)\n",
    "print(tensor.shape)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eszna\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 513])\n",
      "tensor([[[-1.3249, -0.6562, -0.9328,  ..., -1.0165, -0.9106, -0.3370],\n",
      "         [-1.3910,  0.4849, -1.3068,  ..., -1.3775, -0.7459, -0.0086],\n",
      "         [-1.1262, -0.0726, -0.9685,  ..., -1.6376, -1.2930,  0.0669],\n",
      "         ...,\n",
      "         [-1.4456, -0.4105, -1.1261,  ..., -1.6567, -0.5363,  0.8601],\n",
      "         [-0.9522, -0.3815, -0.9671,  ..., -2.9072,  1.0063,  0.8751],\n",
      "         [-0.5490, -0.7015, -0.1915,  ..., -1.7616, -1.4931,  0.6862]],\n",
      "\n",
      "        [[-0.8090, -1.1492,  0.3075,  ..., -1.3865, -0.8674,  0.5745],\n",
      "         [-0.8424, -0.6660, -0.1465,  ..., -0.9639, -0.3047, -0.1680],\n",
      "         [-1.2764, -0.1589, -1.2321,  ..., -2.4243, -0.5671, -0.4900],\n",
      "         ...,\n",
      "         [-0.8678, -0.5011, -0.8002,  ..., -1.8278, -0.4234,  0.1781],\n",
      "         [-0.0087, -1.2541, -0.9698,  ..., -2.2691, -0.7363,  1.1366],\n",
      "         [-0.6734, -0.7599, -0.5021,  ..., -1.2946, -0.8837,  0.4195]],\n",
      "\n",
      "        [[-0.9761, -1.5037, -1.5354,  ..., -1.4493,  0.1945,  0.1282],\n",
      "         [-1.0821, -1.0863, -0.5259,  ..., -1.7962, -0.7185,  0.3115],\n",
      "         [-1.2658, -0.6105, -1.2675,  ..., -2.3624, -1.3346,  0.1306],\n",
      "         ...,\n",
      "         [-0.1513, -0.1358, -1.5970,  ..., -1.9394, -0.0824,  0.4407],\n",
      "         [-1.0066, -0.8643, -1.4687,  ..., -2.4385, -0.8613,  0.7790],\n",
      "         [-0.6464, -0.4280, -0.8708,  ..., -2.0652, -1.1707,  0.2621]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9288, -1.2683, -0.7468,  ..., -1.4854, -1.2006, -0.3441],\n",
      "         [-1.0093, -0.3107,  0.5562,  ..., -1.8378, -0.7773, -0.1728],\n",
      "         [-0.6867, -0.8363, -0.5208,  ..., -1.6931, -0.6362,  0.4278],\n",
      "         ...,\n",
      "         [-0.7024, -0.9661, -0.5619,  ..., -1.4150, -0.8585,  0.2756],\n",
      "         [-0.7736, -0.7688, -0.8500,  ..., -2.4610, -0.3999,  0.5406],\n",
      "         [-0.8860, -0.0843, -0.6241,  ..., -1.7349, -1.3016,  0.2898]],\n",
      "\n",
      "        [[-1.3337, -1.0646, -0.9338,  ..., -1.7228, -0.7313, -0.2713],\n",
      "         [-1.0523,  0.4838, -0.4331,  ..., -1.1566, -1.6499,  0.6002],\n",
      "         [-1.5956, -0.8558, -1.5362,  ..., -2.4059, -1.2077,  0.1636],\n",
      "         ...,\n",
      "         [-0.4113, -0.0173, -0.5015,  ..., -1.8084, -1.1609,  0.0729],\n",
      "         [-0.6728, -1.3357, -0.6845,  ..., -1.8020, -0.3592,  0.2844],\n",
      "         [-0.9129, -0.5744, -0.1390,  ..., -2.1025, -1.4965,  0.3088]],\n",
      "\n",
      "        [[-2.2342, -0.3442, -1.1038,  ..., -1.7264, -0.1408,  0.1764],\n",
      "         [-0.8178,  0.3650,  0.6467,  ..., -1.5826, -0.8147, -0.0168],\n",
      "         [-1.1924, -1.1275, -1.1669,  ..., -1.6390, -1.3905,  0.4967],\n",
      "         ...,\n",
      "         [-1.4424, -0.5428, -0.8356,  ..., -1.1229, -1.1099,  0.3488],\n",
      "         [-0.4510, -0.3122, -1.1861,  ..., -2.6604,  0.8229,  0.1625],\n",
      "         [-1.3036, -0.2660, -0.2027,  ..., -1.9234, -1.9561, -0.0663]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src = th.rand(INPUT_NUM_FRAMES, INPUT_NUM_SHOTS, INPUT_NUM_SAMPLES)\n",
    "target = th.rand(INPUT_NUM_FRAMES, INPUT_NUM_SHOTS, INPUT_NUM_SAMPLES)\n",
    "tranformer = th.nn.Transformer(d_model=INPUT_NUM_SAMPLES, nhead=3, num_encoder_layers=6)\n",
    "output = tranformer(src, target)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 16, 513])\n",
      "tensor([[[[ 0.1607,  0.2079,  0.2222,  ...,  0.3945,  0.3787,  0.1123],\n",
      "          [ 0.1547,  0.3448,  0.3480,  ...,  0.3785,  0.3459,  0.0743],\n",
      "          [ 0.1397,  0.3786,  0.3024,  ...,  0.4181,  0.3964,  0.0537],\n",
      "          ...,\n",
      "          [ 0.1411,  0.3779,  0.1557,  ...,  0.5615,  0.2502,  0.1039],\n",
      "          [ 0.0812,  0.4870,  0.1891,  ...,  0.7161,  0.2516,  0.1618],\n",
      "          [ 0.0300,  0.2879,  0.1963,  ...,  0.5446,  0.0831,  0.1472]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0634,  0.4059,  0.4069,  ...,  0.4795,  0.2878,  0.2010],\n",
      "          [ 0.2176,  0.2998,  0.4785,  ...,  0.5356,  0.3734,  0.0880],\n",
      "          [ 0.1864,  0.4003,  0.5657,  ...,  0.4279,  0.5544,  0.0812],\n",
      "          ...,\n",
      "          [ 0.0837,  0.4768,  0.2333,  ...,  0.1843,  0.3935,  0.1964],\n",
      "          [ 0.0873,  0.2206,  0.4172,  ...,  0.4285,  0.2741,  0.2106],\n",
      "          [ 0.1147,  0.0693,  0.2864,  ...,  0.5617,  0.1415,  0.0370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0654,  0.4711,  0.1993,  ...,  0.3724,  0.3940,  0.1563],\n",
      "          [ 0.0608,  0.3459,  0.3788,  ...,  0.3051,  0.3237,  0.1384],\n",
      "          [ 0.1437,  0.3368,  0.3780,  ...,  0.1308,  0.4384,  0.0850],\n",
      "          ...,\n",
      "          [ 0.2970,  0.2970,  0.4869,  ...,  0.4771,  0.2513,  0.0757],\n",
      "          [ 0.1145,  0.4327,  0.6155,  ...,  0.5815,  0.1104,  0.2292],\n",
      "          [-0.0344,  0.3791,  0.2572,  ...,  0.3126,  0.2763,  0.0472]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2168,  0.2266,  0.2855,  ...,  0.2864,  0.2615,  0.2331],\n",
      "          [ 0.1875,  0.4070,  0.1942,  ...,  0.3177,  0.3346,  0.2107],\n",
      "          [ 0.1585,  0.4433,  0.4445,  ...,  0.3599,  0.4454, -0.0265],\n",
      "          ...,\n",
      "          [-0.0373,  0.4897,  0.2866,  ...,  0.2936,  0.2566,  0.2173],\n",
      "          [-0.0398,  0.5396,  0.2414,  ...,  0.2356,  0.2639,  0.1630],\n",
      "          [ 0.0410,  0.3372,  0.1470,  ...,  0.2091,  0.1372,  0.1422]]],\n",
      "\n",
      "\n",
      "        [[[-0.0234,  0.3509,  0.1805,  ...,  0.3990,  0.2927,  0.1568],\n",
      "          [-0.0193,  0.5748,  0.2013,  ...,  0.4832,  0.3847,  0.1040],\n",
      "          [-0.0014,  0.5748,  0.3230,  ...,  0.2045,  0.5020, -0.0079],\n",
      "          ...,\n",
      "          [ 0.1464,  0.4220,  0.1890,  ...,  0.0601,  0.5683, -0.0704],\n",
      "          [ 0.0672,  0.4895,  0.2237,  ...,  0.0976,  0.5655,  0.0718],\n",
      "          [-0.0569,  0.4065,  0.1422,  ...,  0.1636,  0.2426,  0.0675]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0108,  0.3997,  0.2244,  ...,  0.0484,  0.4316,  0.0900],\n",
      "          [-0.0149,  0.4972,  0.1701,  ...,  0.1960,  0.3267, -0.0157],\n",
      "          [-0.0377,  0.6826,  0.1325,  ...,  0.2340,  0.3565, -0.0313],\n",
      "          ...,\n",
      "          [ 0.1116,  0.4809,  0.3614,  ...,  0.3395,  0.2842,  0.1334],\n",
      "          [ 0.1837,  0.4546,  0.3946,  ...,  0.4206,  0.4029,  0.0409],\n",
      "          [ 0.0618,  0.3412,  0.1904,  ...,  0.2165,  0.4003,  0.0261]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_layer = th.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Reshape the input tensor to match the expected input shape of Conv2d\n",
    "# Conv2d expects input of shape (batch_size, channels, height, width)\n",
    "# Here, we treat INPUT_NUM_FRAMES as batch_size\n",
    "reshaped_tensor = src.view(INPUT_NUM_FRAMES, 1, INPUT_NUM_SHOTS, INPUT_NUM_SAMPLES)\n",
    "\n",
    "# Apply the convolutional layer\n",
    "conv_output = conv_layer(reshaped_tensor)\n",
    "print(conv_output.shape)\n",
    "print(conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 16, 513])\n",
      "torch.Size([8, 16, 513])\n",
      "torch.Size([8, 16, 513])\n",
      "tensor([[[-0.9797, -0.1126, -0.2714,  ..., -1.5197, -0.4563, -0.3178],\n",
      "         [-1.2209, -0.1903, -1.0866,  ..., -2.2133, -1.3801,  0.6142],\n",
      "         [-0.7903, -0.1430, -1.1058,  ..., -2.1902, -0.7885, -0.0133],\n",
      "         ...,\n",
      "         [-1.2281, -0.6090, -1.3023,  ..., -2.0308, -0.4505,  0.7915],\n",
      "         [-0.9986, -1.6100, -1.1983,  ..., -1.4816, -1.1801,  0.2326],\n",
      "         [-0.3887,  0.2142, -1.6310,  ..., -1.5029, -1.0836,  0.1423]],\n",
      "\n",
      "        [[-1.3195,  0.0901, -1.0481,  ..., -2.2466, -0.9455, -0.0872],\n",
      "         [-0.1212, -0.0580, -0.7166,  ..., -1.8695,  0.1749, -0.1129],\n",
      "         [-0.0470, -0.7651, -0.8520,  ..., -1.6547, -0.5619,  0.1654],\n",
      "         ...,\n",
      "         [-0.9004, -0.1400, -1.2482,  ..., -1.3382, -0.6251,  0.2723],\n",
      "         [-0.5011, -1.0410, -0.7135,  ..., -1.8507, -1.0604,  0.8196],\n",
      "         [-0.8209, -0.2629, -1.1446,  ..., -2.6196,  0.0800,  0.3325]],\n",
      "\n",
      "        [[-0.8772, -0.9886, -0.6920,  ..., -1.3973, -0.6907,  0.4108],\n",
      "         [-0.8741, -0.6773, -0.3293,  ..., -1.2523, -0.2279, -0.0184],\n",
      "         [-0.5000, -0.3996, -0.8686,  ..., -1.8236, -0.9682,  0.1503],\n",
      "         ...,\n",
      "         [-2.0711, -0.6173, -1.3976,  ..., -1.0872, -1.2691,  0.2084],\n",
      "         [-1.0553, -0.6714, -1.0280,  ..., -2.4127, -0.6197,  1.2203],\n",
      "         [-0.1506, -0.9507, -0.9278,  ..., -2.3753, -1.2171,  0.2809]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1917,  0.1693,  0.0112,  ..., -1.3659, -0.7727,  0.9964],\n",
      "         [-1.3249, -0.2426, -0.4486,  ..., -2.2872,  0.2353,  1.0360],\n",
      "         [ 0.0498, -0.6343, -0.8691,  ..., -1.7654, -1.7818,  1.0230],\n",
      "         ...,\n",
      "         [-1.4247, -0.7943, -1.7622,  ..., -2.4141, -1.5522,  0.5868],\n",
      "         [-0.9594, -1.0381, -0.7191,  ..., -1.1701, -1.5042,  0.6929],\n",
      "         [-0.9955, -0.9832, -1.2621,  ..., -1.5642, -1.2415,  0.6932]],\n",
      "\n",
      "        [[-1.6572,  0.1085, -0.9768,  ..., -1.4846, -1.6294,  0.3329],\n",
      "         [-1.3517, -0.4880, -0.9483,  ..., -1.2810, -1.0603,  0.5444],\n",
      "         [-0.4561, -1.1196, -1.8832,  ..., -1.4516, -0.8488,  1.0165],\n",
      "         ...,\n",
      "         [-1.0768, -0.0947, -1.7971,  ..., -1.0139, -1.0214, -0.1259],\n",
      "         [-0.8100, -1.1007, -0.8218,  ..., -2.1555, -0.4471,  0.4455],\n",
      "         [-0.4469, -0.5832, -1.6101,  ..., -2.4902, -0.8371,  0.1873]],\n",
      "\n",
      "        [[-0.9018, -0.1319, -1.0703,  ..., -1.7674, -0.9056,  0.6516],\n",
      "         [-1.3071, -0.4761, -0.8977,  ..., -0.8944, -1.3339,  0.3358],\n",
      "         [-0.6175, -0.2228, -0.4489,  ..., -2.5032, -1.0032, -0.2650],\n",
      "         ...,\n",
      "         [-0.8831, -0.4208, -1.4862,  ..., -1.8069, -0.3263, -0.0895],\n",
      "         [-0.9225, -1.4637, -0.5692,  ..., -1.6251, -0.2274,  0.5463],\n",
      "         [-0.5129, -0.9452, -0.0351,  ..., -2.1651, -1.0593, -0.1912]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Full Flow\n",
    "# Reshape the input tensor to match the expected input shape of Conv2d\n",
    "# Conv2d expects input of shape (batch_size, channels, height, width)\n",
    "# Here, we treat INPUT_NUM_FRAMES as batch_size\n",
    "reshaped_tensor = src.view(INPUT_NUM_FRAMES, 1, INPUT_NUM_SHOTS, INPUT_NUM_SAMPLES)\n",
    "\n",
    "# Apply the convolutional layer\n",
    "conv_output = conv_layer(reshaped_tensor)\n",
    "print(conv_output.shape)\n",
    "\n",
    "# Reshape the output tensor to match the expected input shape of Transformer\n",
    "# Transformer expects input of shape (sequence_length, batch_size, d_model)\n",
    "# Here, we treat INPUT_NUM_SHOTS as sequence_length and INPUT_NUM_SAMPLES as d_model\n",
    "reshaped_tensor = conv_output.view(INPUT_NUM_FRAMES, INPUT_NUM_SHOTS, INPUT_NUM_SAMPLES)    \n",
    "print(reshaped_tensor.shape)\n",
    "\n",
    "# Apply the transformer\n",
    "output = tranformer(reshaped_tensor, reshaped_tensor)\n",
    "print(output.shape)\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
